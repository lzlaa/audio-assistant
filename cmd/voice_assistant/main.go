package main

import (
	"context"
	"encoding/binary"
	"fmt"
	"log"
	"os"
	"os/signal"
	"path/filepath"
	"sync"
	"syscall"
	"time"

	"audio-assistant/internal/asr"
	"audio-assistant/internal/audio"
	"audio-assistant/internal/llm"
	"audio-assistant/internal/state"
	"audio-assistant/internal/tts"
	"audio-assistant/internal/vad"
)

// VoiceAssistant è¯­éŸ³åŠ©æ‰‹ç»“æ„ä½“
type VoiceAssistant struct {
	// éŸ³é¢‘æ¨¡å—
	audioInput   *audio.Input
	audioOutput  *audio.AudioOutput
	stateManager *state.Manager

	// API å®¢æˆ·ç«¯
	vadClient *vad.Client
	asrClient *asr.Client
	llmClient *llm.OpenAISDKClient
	ttsClient *tts.TTSClient

	// æ§åˆ¶
	ctx          context.Context
	cancel       context.CancelFunc
	shutdownChan chan bool

	// çŠ¶æ€å˜é‡
	isListening         bool
	conversationHistory []llm.Message

	// æ‰“æ–­æ£€æµ‹çŠ¶æ€
	interruptDetectionStart time.Time
	isDetectingInterrupt    bool

	// æ’­æ”¾æ§åˆ¶
	playbackCtx    context.Context
	playbackCancel context.CancelFunc

	// åŒæ­¥æ§åˆ¶
	mu sync.RWMutex

	// é…ç½®å‚æ•°
	config *Config
}

// Config é…ç½®ç»“æ„ä½“
type Config struct {
	// API é…ç½®
	OpenAIAPIKey string
	VADServerURL string

	// éŸ³é¢‘é…ç½®
	VADThreshold            float64
	MinSpeechDurationMs     int
	MinSilenceDurationMs    int
	MaxRecordingDurationSec int

	// æ‰“æ–­æ§åˆ¶é…ç½®
	AllowInterrupt         bool    // æ˜¯å¦å…è®¸æ‰“æ–­æ’­æ”¾
	InterruptThreshold     float64 // æ‰“æ–­æ£€æµ‹é˜ˆå€¼ï¼ˆæ›´é«˜=æ›´éš¾æ‰“æ–­ï¼‰
	InterruptMinDurationMs int     // æ‰“æ–­æœ€å°æŒç»­æ—¶é—´

	// LLM é…ç½®
	LLMModel       string
	LLMTemperature float32
	SystemPrompt   string

	// TTS é…ç½®
	TTSModel string
	TTSVoice string
	TTSSpeed float64

	// è°ƒè¯•é…ç½®
	SaveAudioFiles bool
	AudioOutputDir string
}

// getDefaultConfig è·å–é»˜è®¤é…ç½®
func getDefaultConfig() *Config {
	return &Config{
		VADServerURL:            "http://localhost:8080",
		VADThreshold:            0.5,
		MinSpeechDurationMs:     500,
		MinSilenceDurationMs:    1000,
		MaxRecordingDurationSec: 30,
		// æ‰“æ–­æ§åˆ¶é…ç½®
		AllowInterrupt:         true, // é»˜è®¤å…è®¸æ‰“æ–­
		InterruptThreshold:     0.7,  // è¾ƒé«˜çš„é˜ˆå€¼ï¼Œé¿å…è¯¯è§¦å‘
		InterruptMinDurationMs: 200,  // éœ€è¦æŒç»­200msçš„è¯­éŸ³æ‰èƒ½æ‰“æ–­
		LLMModel:               "gpt-4o-mini",
		LLMTemperature:         0.7,
		SystemPrompt:           "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´ã€å‹å¥½çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚",
		TTSModel:               "tts-1",
		TTSVoice:               "alloy",
		TTSSpeed:               1.0,
		SaveAudioFiles:         false,
		AudioOutputDir:         "temp",
	}
}

// NewVoiceAssistant åˆ›å»ºæ–°çš„è¯­éŸ³åŠ©æ‰‹
func NewVoiceAssistant(config *Config) (*VoiceAssistant, error) {
	// åˆ›å»ºè¾“å‡ºç›®å½•
	if config.SaveAudioFiles {
		if err := os.MkdirAll(config.AudioOutputDir, 0755); err != nil {
			return nil, fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %w", err)
		}
	}

	// åˆ›å»ºçŠ¶æ€ç®¡ç†å™¨
	stateManager := state.NewManager()

	// åˆ›å»ºéŸ³é¢‘æ¨¡å—
	audioInput, err := audio.NewInput()
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºéŸ³é¢‘è¾“å…¥å¤±è´¥: %w", err)
	}

	audioOutput, err := audio.NewAudioOutput(16000)
	if err != nil {
		audioInput.Close()
		return nil, fmt.Errorf("åˆ›å»ºéŸ³é¢‘è¾“å‡ºå¤±è´¥: %w", err)
	}

	// åˆ›å»ºå®¢æˆ·ç«¯
	vadClient := vad.NewClient(config.VADServerURL)

	asrClient := asr.NewClient(config.OpenAIAPIKey)

	llmConfig := &llm.Config{
		APIKey: config.OpenAIAPIKey,
	}
	llmClient := llm.NewClient(llmConfig)

	ttsClient := tts.NewTTSClient(config.OpenAIAPIKey)
	ttsClient.SetModel(config.TTSModel)
	ttsClient.SetVoice(config.TTSVoice)
	ttsClient.SetSpeed(config.TTSSpeed)

	ctx, cancel := context.WithCancel(context.Background())

	return &VoiceAssistant{
		audioInput:          audioInput,
		audioOutput:         audioOutput,
		stateManager:        stateManager,
		vadClient:           vadClient,
		asrClient:           asrClient,
		llmClient:           llmClient,
		ttsClient:           ttsClient,
		ctx:                 ctx,
		cancel:              cancel,
		shutdownChan:        make(chan bool, 1),
		isListening:         false,
		conversationHistory: make([]llm.Message, 0),
		config:              config,
	}, nil
}

// Start å¯åŠ¨è¯­éŸ³åŠ©æ‰‹
func (va *VoiceAssistant) Start(ctx context.Context) error {
	// æ£€æŸ¥ VAD æœåŠ¡æ˜¯å¦å¯ç”¨
	if err := va.checkVADService(); err != nil {
		return fmt.Errorf("VADæœåŠ¡æ£€æŸ¥å¤±è´¥: %w", err)
	}

	fmt.Println("=== è¯­éŸ³åŠ©æ‰‹å·²å°±ç»ªï¼Œæ‚¨å¯ä»¥å¼€å§‹å¯¹è¯ ===")

	// å¯åŠ¨ä¸»å¤„ç†å¾ªç¯
	go va.processingLoop()

	// ç­‰å¾…å…³é—­ä¿¡å·
	select {
	case <-ctx.Done():
		return ctx.Err()
	case <-va.shutdownChan:
		return nil
	}
}

// checkVADService æ£€æŸ¥VADæœåŠ¡æ˜¯å¦å¯ç”¨
func (va *VoiceAssistant) checkVADService() error {
	tempAudio := make([]float32, 8000) // 0.5ç§’çš„é™éŸ³
	tempFile, err := va.saveAudioToTempFile(tempAudio)
	if err != nil {
		return err
	}
	defer os.Remove(tempFile)

	vadReq := &vad.DetectRequest{
		Threshold:            va.config.VADThreshold,
		MinSpeechDurationMs:  va.config.MinSpeechDurationMs,
		MinSilenceDurationMs: va.config.MinSilenceDurationMs,
	}

	_, err = va.vadClient.HasSpeech(tempFile, vadReq)
	return err
}

// processingLoop ä¸»å¤„ç†å¾ªç¯
func (va *VoiceAssistant) processingLoop() {
	audioBuffer := make([][]float32, 0)
	recordingStart := time.Time{}
	silenceStart := time.Time{}

	ticker := time.NewTicker(50 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case <-va.ctx.Done():
			va.shutdownChan <- true
			return

		case <-ticker.C:
			// è¯»å–éŸ³é¢‘æ•°æ®
			audioData, err := va.audioInput.Read()
			if err != nil {
				log.Printf("è¯»å–éŸ³é¢‘æ•°æ®å¤±è´¥: %v", err)
				continue
			}

			currentState := va.stateManager.GetState()

			switch currentState {
			case state.StateIdle, state.StateListening:
				// æ£€æµ‹è¯­éŸ³æ´»åŠ¨
				hasSpeech, err := va.detectSpeechActivity(audioData)
				if err != nil {
					log.Printf("è¯­éŸ³æ´»åŠ¨æ£€æµ‹å¤±è´¥: %v", err)
					continue
				}

				if hasSpeech {
					// æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹æˆ–ç»§ç»­å½•éŸ³
					if !va.isListening {
						va.isListening = true
						recordingStart = time.Now()
						audioBuffer = audioBuffer[:0]
						va.stateManager.SetState(state.StateListening)
						fmt.Println("ğŸ¤ å¼€å§‹å½•éŸ³...")
					}

					audioBuffer = append(audioBuffer, audioData)
					silenceStart = time.Time{} // é‡ç½®é™éŸ³å¼€å§‹æ—¶é—´

					// æ£€æŸ¥å½•éŸ³æ—¶é•¿é™åˆ¶
					if time.Since(recordingStart) > time.Duration(va.config.MaxRecordingDurationSec)*time.Second {
						fmt.Println("â° å½•éŸ³æ—¶é—´è¶…è¿‡é™åˆ¶ï¼Œè‡ªåŠ¨ç»“æŸå½•éŸ³")
						va.processRecording(audioBuffer)
						va.resetRecording(&audioBuffer, &recordingStart, &silenceStart)
					}
				} else if va.isListening {
					// åœ¨å½•éŸ³ä¸­æ£€æµ‹åˆ°é™éŸ³
					if silenceStart.IsZero() {
						silenceStart = time.Now()
					}

					audioBuffer = append(audioBuffer, audioData)

					// æ£€æŸ¥é™éŸ³æ—¶é•¿
					if time.Since(silenceStart) > time.Duration(va.config.MinSilenceDurationMs)*time.Millisecond {
						fmt.Println("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œç»“æŸå½•éŸ³")
						va.processRecording(audioBuffer)
						va.resetRecording(&audioBuffer, &recordingStart, &silenceStart)
					}
				}

			case state.StateSpeaking:
				// æ’­æ”¾ä¸­ï¼Œæ£€æµ‹æ‰“æ–­ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„æ¡ä»¶ï¼‰
				if va.config.AllowInterrupt {
					hasInterrupt, err := va.detectInterrupt(audioData)
					if err == nil && hasInterrupt {
						// æ£€æµ‹åˆ°æ½œåœ¨æ‰“æ–­ï¼Œå¼€å§‹è®¡æ—¶éªŒè¯
						if !va.isDetectingInterrupt {
							va.isDetectingInterrupt = true
							va.interruptDetectionStart = time.Now()
							fmt.Println("ğŸ¯ æ£€æµ‹åˆ°å¯èƒ½çš„æ‰“æ–­...")
						}

						// æ£€æŸ¥æ‰“æ–­æŒç»­æ—¶é—´
						if time.Since(va.interruptDetectionStart) > time.Duration(va.config.InterruptMinDurationMs)*time.Millisecond {
							fmt.Println("ğŸš« ç¡®è®¤ç”¨æˆ·æ‰“æ–­")
							va.handleInterrupt()
							va.isDetectingInterrupt = false
						}
					} else {
						// æ²¡æœ‰æ£€æµ‹åˆ°æ‰“æ–­ï¼Œé‡ç½®çŠ¶æ€
						if va.isDetectingInterrupt {
							va.isDetectingInterrupt = false
							fmt.Println("ğŸ“¢ ç»§ç»­æ’­æ”¾...")
						}
					}
				}
			}
		}
	}
}

// detectSpeechActivity æ£€æµ‹è¯­éŸ³æ´»åŠ¨
func (va *VoiceAssistant) detectSpeechActivity(audioData []float32) (bool, error) {
	// å°† float32 éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
	tempFile, err := va.saveAudioToTempFile(audioData)
	if err != nil {
		return false, err
	}
	defer os.Remove(tempFile)

	// è°ƒç”¨ VAD æœåŠ¡
	vadReq := &vad.DetectRequest{
		Threshold:            va.config.VADThreshold,
		MinSpeechDurationMs:  va.config.MinSpeechDurationMs,
		MinSilenceDurationMs: va.config.MinSilenceDurationMs,
	}

	hasSpeech, err := va.vadClient.HasSpeech(tempFile, vadReq)
	if err != nil {
		return false, err
	}

	return hasSpeech, nil
}

// detectInterrupt æ£€æµ‹æ‰“æ–­ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼ï¼‰
func (va *VoiceAssistant) detectInterrupt(audioData []float32) (bool, error) {
	if !va.config.AllowInterrupt {
		return false, nil
	}

	// å°† float32 éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
	tempFile, err := va.saveAudioToTempFile(audioData)
	if err != nil {
		return false, err
	}
	defer os.Remove(tempFile)

	// ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ‰“æ–­æ£€æµ‹å‚æ•°
	vadReq := &vad.DetectRequest{
		Threshold:            va.config.InterruptThreshold,     // æ›´é«˜çš„é˜ˆå€¼
		MinSpeechDurationMs:  va.config.InterruptMinDurationMs, // æ›´é•¿çš„æœ€å°æŒç»­æ—¶é—´
		MinSilenceDurationMs: va.config.MinSilenceDurationMs,
	}

	hasSpeech, err := va.vadClient.HasSpeech(tempFile, vadReq)
	if err != nil {
		return false, err
	}

	return hasSpeech, nil
}

// saveAudioToTempFile å°†éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
func (va *VoiceAssistant) saveAudioToTempFile(audioData []float32) (string, error) {
	// åˆ›å»ºä¸´æ—¶æ–‡ä»¶
	tempFile, err := os.CreateTemp("temp", "audio_*.wav")
	if err != nil {
		return "", err
	}
	defer tempFile.Close()

	// å†™å…¥ç®€å•çš„ WAV å¤´
	sampleRate := 16000
	numChannels := 1
	bitsPerSample := 32

	dataSize := len(audioData) * 4
	fileSize := 36 + dataSize

	// WAV å¤´éƒ¨
	header := make([]byte, 44)
	copy(header[0:4], []byte("RIFF"))
	binary.LittleEndian.PutUint32(header[4:8], uint32(fileSize))
	copy(header[8:12], []byte("WAVE"))
	copy(header[12:16], []byte("fmt "))
	binary.LittleEndian.PutUint32(header[16:20], 16)
	binary.LittleEndian.PutUint16(header[20:22], 3) // IEEE float
	binary.LittleEndian.PutUint16(header[22:24], uint16(numChannels))
	binary.LittleEndian.PutUint32(header[24:28], uint32(sampleRate))
	binary.LittleEndian.PutUint32(header[28:32], uint32(sampleRate*numChannels*bitsPerSample/8))
	binary.LittleEndian.PutUint16(header[32:34], uint16(numChannels*bitsPerSample/8))
	binary.LittleEndian.PutUint16(header[34:36], uint16(bitsPerSample))
	copy(header[36:40], []byte("data"))
	binary.LittleEndian.PutUint32(header[40:44], uint32(dataSize))

	// å†™å…¥å¤´éƒ¨
	if _, err := tempFile.Write(header); err != nil {
		return "", err
	}

	// å†™å…¥éŸ³é¢‘æ•°æ®
	for _, sample := range audioData {
		if err := binary.Write(tempFile, binary.LittleEndian, sample); err != nil {
			return "", err
		}
	}

	return tempFile.Name(), nil
}

// processRecording å¤„ç†å½•éŸ³
func (va *VoiceAssistant) processRecording(audioBuffer [][]float32) {
	va.stateManager.SetState(state.StateProcessing)

	go func() {
		defer va.stateManager.SetState(state.StateIdle)

		// åˆå¹¶éŸ³é¢‘ç¼“å†²åŒº
		var combinedAudio []float32
		for _, chunk := range audioBuffer {
			combinedAudio = append(combinedAudio, chunk...)
		}

		if len(combinedAudio) == 0 {
			log.Println("éŸ³é¢‘ç¼“å†²åŒºä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
			return
		}

		fmt.Println("ğŸ”„ æ­£åœ¨å¤„ç†éŸ³é¢‘...")

		// ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
		var audioFilePath string
		if va.config.SaveAudioFiles {
			audioFilePath = va.saveRecordedAudio(combinedAudio)
		}

		// 1. ASR - è¯­éŸ³è½¬æ–‡æœ¬
		text, err := va.performASR(combinedAudio)
		if err != nil {
			log.Printf("è¯­éŸ³è¯†åˆ«å¤±è´¥: %v", err)
			va.playErrorMessage("æŠ±æ­‰ï¼Œè¯­éŸ³è¯†åˆ«å¤±è´¥äº†")
			return
		}

		if text == "" {
			log.Println("è¯†åˆ«åˆ°ç©ºæ–‡æœ¬ï¼Œè·³è¿‡å¤„ç†")
			return
		}

		fmt.Printf("ğŸ‘¤ ç”¨æˆ·: %s\n", text)

		// 2. LLM - ç”Ÿæˆå›å¤
		response, err := va.performLLM(text)
		if err != nil {
			log.Printf("LLMå¤„ç†å¤±è´¥: %v", err)
			va.playErrorMessage("æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚")
			return
		}

		fmt.Printf("ğŸ¤– åŠ©æ‰‹: %s\n", response)

		// è®°å½•å¯¹è¯æ—¥å¿—
		if va.config.SaveAudioFiles {
			va.logConversation(text, response, audioFilePath)
		}

		// 3. TTS - æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾
		if err := va.performTTS(response); err != nil {
			log.Printf("TTSå¤„ç†å¤±è´¥: %v", err)
			va.playErrorMessage("æŠ±æ­‰ï¼Œè¯­éŸ³åˆæˆå¤±è´¥äº†")
			return
		}
	}()
}

// performASR æ‰§è¡Œè¯­éŸ³è¯†åˆ«
func (va *VoiceAssistant) performASR(audioData []float32) (string, error) {
	// å°†éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
	tempFile, err := va.saveAudioToTempFile(audioData)
	if err != nil {
		return "", err
	}
	defer os.Remove(tempFile)

	// è°ƒç”¨ ASR
	req := &asr.TranscribeRequest{
		Language: "zh",
		Model:    "whisper-1",
	}

	result, err := va.asrClient.TranscribeFile(va.ctx, tempFile, req)
	if err != nil {
		return "", err
	}

	return result.Text, nil
}

// performLLM æ‰§è¡ŒLLMå¯¹è¯
func (va *VoiceAssistant) performLLM(userText string) (string, error) {
	va.mu.Lock()
	defer va.mu.Unlock()

	// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
	va.conversationHistory = append(va.conversationHistory, llm.Message{
		Role:    "user",
		Content: userText,
	})

	// å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºï¼‰
	messages := []llm.Message{
		{
			Role:    "system",
			Content: va.config.SystemPrompt,
		},
	}
	messages = append(messages, va.conversationHistory...)

	// è°ƒç”¨ LLM
	req := &llm.ChatRequest{
		Model:       va.config.LLMModel,
		Messages:    messages,
		Temperature: va.config.LLMTemperature,
		MaxTokens:   500,
	}

	result, err := va.llmClient.ChatCompletion(va.ctx, req)
	if err != nil {
		return "", err
	}

	response := result.Choices[0].Message.Content

	// æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
	va.conversationHistory = append(va.conversationHistory, llm.Message{
		Role:    "assistant",
		Content: response,
	})

	// é™åˆ¶å†å²é•¿åº¦
	if len(va.conversationHistory) > 20 {
		va.conversationHistory = va.conversationHistory[2:]
	}

	return response, nil
}

// performTTS æ‰§è¡Œæ–‡æœ¬è½¬è¯­éŸ³
func (va *VoiceAssistant) performTTS(text string) error {
	va.stateManager.SetState(state.StateSpeaking)
	defer va.stateManager.SetState(state.StateIdle)

	// åˆ›å»ºæ’­æ”¾ä¸“ç”¨çš„ä¸Šä¸‹æ–‡
	va.mu.Lock()
	va.playbackCtx, va.playbackCancel = context.WithCancel(va.ctx)
	playCtx := va.playbackCtx
	va.mu.Unlock()

	defer func() {
		va.mu.Lock()
		if va.playbackCancel != nil {
			va.playbackCancel()
			va.playbackCancel = nil
			va.playbackCtx = nil
		}
		va.mu.Unlock()
	}()

	// è°ƒç”¨ TTS
	audioData, err := va.ttsClient.SynthesizeText(playCtx, text, tts.FormatWAV)
	if err != nil {
		return err
	}

	// ä¿å­˜ TTS éŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if va.config.SaveAudioFiles {
		timestamp := time.Now().Format("20060102_150405")
		filename := filepath.Join(va.config.AudioOutputDir, fmt.Sprintf("tts_%s.wav", timestamp))
		if err := os.WriteFile(filename, audioData, 0644); err != nil {
			log.Printf("ä¿å­˜ TTS éŸ³é¢‘å¤±è´¥: %v", err)
		}
	}

	// æ’­æ”¾éŸ³é¢‘ - ä½¿ç”¨æ’­æ”¾ä¸“ç”¨ä¸Šä¸‹æ–‡
	err = va.audioOutput.PlayAudioData(playCtx, audioData, 16000)
	if err != nil && err != context.Canceled {
		return fmt.Errorf("æ’­æ”¾éŸ³é¢‘å¤±è´¥: %w", err)
	}

	if err == context.Canceled {
		fmt.Println("ğŸ›‘ éŸ³é¢‘æ’­æ”¾è¢«æ‰“æ–­")
	} else {
		fmt.Println("ğŸ”Š è¯­éŸ³æ’­æ”¾å®Œæˆ")
	}

	return nil
}

// playErrorMessage æ’­æ”¾é”™è¯¯æ¶ˆæ¯
func (va *VoiceAssistant) playErrorMessage(message string) {
	if err := va.performTTS(message); err != nil {
		log.Printf("æ’­æ”¾é”™è¯¯æ¶ˆæ¯å¤±è´¥: %v", err)
	}
}

// resetRecording é‡ç½®å½•éŸ³çŠ¶æ€
func (va *VoiceAssistant) resetRecording(audioBuffer *[][]float32, recordingStart, silenceStart *time.Time) {
	va.isListening = false
	*audioBuffer = (*audioBuffer)[:0]
	*recordingStart = time.Time{}
	*silenceStart = time.Time{}
	va.stateManager.SetState(state.StateIdle)
}

// handleInterrupt å¤„ç†æ‰“æ–­
func (va *VoiceAssistant) handleInterrupt() {
	va.mu.Lock()
	defer va.mu.Unlock()

	// å–æ¶ˆæ’­æ”¾ä¸Šä¸‹æ–‡ï¼ˆè¿™ä¼šåœæ­¢éŸ³é¢‘æ’­æ”¾ï¼‰
	if va.playbackCancel != nil {
		va.playbackCancel()
		va.playbackCancel = nil
		va.playbackCtx = nil
	}

	// åŒæ—¶è°ƒç”¨éŸ³é¢‘è¾“å‡ºçš„åœæ­¢æ–¹æ³•ï¼ˆåŒé‡ä¿é™©ï¼‰
	va.audioOutput.Stop()

	// é‡ç½®æ‰€æœ‰çŠ¶æ€
	va.isDetectingInterrupt = false
	va.interruptDetectionStart = time.Time{}
	va.stateManager.SetState(state.StateIdle)

	fmt.Println("ğŸ›‘ æ’­æ”¾å·²åœæ­¢ï¼Œå¯ä»¥å¼€å§‹æ–°çš„å¯¹è¯")
}

// saveRecordedAudio ä¿å­˜å½•éŸ³
func (va *VoiceAssistant) saveRecordedAudio(audioData []float32) string {
	timestamp := time.Now().Format("20060102_150405")
	filename := filepath.Join(va.config.AudioOutputDir, fmt.Sprintf("recording_%s.wav", timestamp))

	tempFile, err := va.saveAudioToTempFile(audioData)
	if err != nil {
		log.Printf("ä¿å­˜å½•éŸ³å¤±è´¥: %v", err)
		return ""
	}

	// å¤åˆ¶ä¸´æ—¶æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
	data, err := os.ReadFile(tempFile)
	if err != nil {
		log.Printf("è¯»å–ä¸´æ—¶æ–‡ä»¶å¤±è´¥: %v", err)
		os.Remove(tempFile)
		return ""
	}

	if err := os.WriteFile(filename, data, 0644); err != nil {
		log.Printf("ä¿å­˜å½•éŸ³æ–‡ä»¶å¤±è´¥: %v", err)
		os.Remove(tempFile)
		return ""
	}

	os.Remove(tempFile)
	return filename
}

// logConversation è®°å½•å¯¹è¯
func (va *VoiceAssistant) logConversation(userText, assistantText, audioFile string) {
	logFile := filepath.Join(va.config.AudioOutputDir, "conversation.log")

	timestamp := time.Now().Format("2006-01-02 15:04:05")
	logEntry := fmt.Sprintf("[%s] User: %s\n[%s] Assistant: %s\n",
		timestamp, userText, timestamp, assistantText)

	if audioFile != "" {
		logEntry += fmt.Sprintf("[%s] Audio: %s\n", timestamp, audioFile)
	}
	logEntry += "---\n"

	file, err := os.OpenFile(logFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		log.Printf("è®°å½•å¯¹è¯æ—¥å¿—å¤±è´¥: %v", err)
		return
	}
	defer file.Close()

	if _, err := file.WriteString(logEntry); err != nil {
		log.Printf("å†™å…¥å¯¹è¯æ—¥å¿—å¤±è´¥: %v", err)
	}
}

// Stop åœæ­¢è¯­éŸ³åŠ©æ‰‹
func (va *VoiceAssistant) Stop() error {
	log.Println("æ­£åœ¨åœæ­¢è¯­éŸ³åŠ©æ‰‹...")

	// å–æ¶ˆä¸Šä¸‹æ–‡
	va.cancel()

	// å…³é—­éŸ³é¢‘æ¨¡å—
	if va.audioInput != nil {
		va.audioInput.Close()
	}

	if va.audioOutput != nil {
		va.audioOutput.Close()
	}

	log.Println("è¯­éŸ³åŠ©æ‰‹å·²åœæ­¢")
	return nil
}

func main() {
	// ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
	config := getDefaultConfig()

	if apiKey := os.Getenv("OPENAI_API_KEY"); apiKey != "" {
		config.OpenAIAPIKey = apiKey
	}

	if vadURL := os.Getenv("VAD_SERVER_URL"); vadURL != "" {
		config.VADServerURL = vadURL
	}

	// å¯ç”¨éŸ³é¢‘æ–‡ä»¶ä¿å­˜ï¼ˆç”¨äºè°ƒè¯•ï¼‰
	config.SaveAudioFiles = false

	// æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦ç¦ç”¨æ‰“æ–­åŠŸèƒ½
	if disableInterrupt := os.Getenv("DISABLE_INTERRUPT"); disableInterrupt == "true" {
		config.AllowInterrupt = false
		fmt.Println("ğŸ”’ æ‰“æ–­åŠŸèƒ½å·²ç¦ç”¨")
	}

	// åˆ›å»ºè¯­éŸ³åŠ©æ‰‹
	assistant, err := NewVoiceAssistant(config)
	if err != nil {
		log.Fatalf("åˆ›å»ºè¯­éŸ³åŠ©æ‰‹å¤±è´¥: %v", err)
	}

	// è®¾ç½®ä¿¡å·å¤„ç†
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)

	go func() {
		<-sigChan
		fmt.Println("\næ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
		cancel()
		assistant.Stop()
	}()

	// å¯åŠ¨è¯­éŸ³åŠ©æ‰‹
	if err := assistant.Start(ctx); err != nil {
		log.Fatalf("å¯åŠ¨è¯­éŸ³åŠ©æ‰‹å¤±è´¥: %v", err)
	}
}
