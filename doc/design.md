# 语音助手项目方案设计文档

## 一、总体架构

```
┌────────────┐      ┌────────────┐      ┌────────────┐      ┌────────────┐      ┌────────────┐
│ 麦克风输入 │─音频→│ 语音活动检测│─音频→│ 语音识别ASR │─文本→│ 语言模型LLM │─文本→│ 文本转语音TTS│─音频→│ 扬声器播放 │
└────────────┘      └────────────┘      └────────────┘      └────────────┘      └────────────┘
         ↑                                                                                   │
         └─────────────────────<─────打断检测─────<───────────────────────────────────────────┘
```

- **麦克风输入**：采集用户语音。
- **VAD（语音活动检测）**：用 Silero VAD 检测用户是否在说话，自动分割语音片段。
- **ASR（语音识别）**：用 OpenAI Whisper API 将语音转为文本。
- **LLM（大语言模型）**：用 OpenAI GPT API 生成回复文本。
- **TTS（文本转语音）**：用 OpenAI/TTS API 将回复文本转为语音。
- **扬声器播放**：播放助手回复。
- **打断机制**：如果用户在助手说话时再次说话，立即打断助手发言，重新进入识别流程。

---

## 二、模块划分

1. **音频采集模块**  
   - 负责从本地麦克风实时采集音频流。
   - 技术选型：Go + [portaudio-go](https://github.com/gordonklaus/portaudio)
   - 状态：✅ 已完成

2. **VAD模块（Silero VAD）**  
   - 检测音频流中何时开始/结束说话。
   - 技术选型：Go 调用 Python Silero VAD（通过 HTTP 通信）
   - 状态：✅ 已完成

3. **ASR模块（Whisper）**  
   - 将检测到的语音片段发送到 OpenAI Whisper API，获取文本。
   - 技术选型：Go HTTP 客户端
   - 状态：✅ 已完成

4. **LLM模块（GPT）**  
   - 将识别到的文本发送到 OpenAI GPT API，获取回复文本。
   - 技术选型：Go HTTP 客户端
   - 状态：✅ 已完成

5. **TTS模块**  
   - 将回复文本发送到 TTS API，获取语音音频。
   - 技术选型：Go HTTP 客户端
   - 状态：✅ 已完成

6. **音频播放模块**  
   - 播放助手回复的音频。
   - 技术选型：Go + portaudio-go
   - 状态：✅ 已完成

7. **打断控制模块**  
   - 检测用户是否在助手说话时插话，若有则立即停止播放并重新进入识别流程。
   - 技术选型：Go 协程、通道、状态机
   - 状态：✅ 已完成

8. **主控流程/状态机**  
   - 协调各模块，保证流程顺畅，处理异常和状态切换。
   - 状态：✅ 已完成

---

## 三、技术选型说明

- **Go语言**：主程序开发，易于并发、跨平台。
- **portaudio-go**：音频采集与播放。
- **Silero VAD**：用 Python 实现，Go 通过 gRPC/HTTP/子进程调用。
- **OpenAI API**：Whisper（ASR）、GPT（LLM）、TTS。
- **gRPC/HTTP**：Go 与 Python 进程通信。

---

## 四、数据流与状态流

1. **采集音频流** → 2. **VAD检测说话段** → 3. **说话结束后自动送ASR** → 4. **ASR转文本** → 5. **LLM生成回复** → 6. **TTS转语音** → 7. **播放音频**  
   - **播放期间**：持续监听麦克风，若检测到用户说话，立即打断播放，回到第1步。

---

## 五、关键难点说明

- **VAD与Go集成**：Silero VAD官方无Go实现，需用Python服务，Go通过gRPC/HTTP/子进程调用。
- **打断机制**：需用Go并发特性，播放时持续监听VAD，检测到说话立即打断。
- **音频流管理**：需处理音频缓冲、格式转换等细节。
- **API调用速率与错误处理**：需处理API延迟、失败重试等。

---

## 六、TODO List

### 1. 环境准备
- [x] 安装 Go 环境
- [x] 安装 Python 环境
- [x] 安装 portaudio（Go 和 Python 都需）
- [ ] 注册 OpenAI API Key
- [ ] 下载/准备 Silero VAD Python 脚本

### 2. VAD 服务
- [x] 用 Python 实现 Silero VAD 服务（HTTP 方式）
- [x] 测试本地音频流通过 VAD 服务能正确检测说话段

### 3. Go 主程序
- [x] 音频采集模块（portaudio-go）
- [x] 音频播放模块（portaudio-go）
- [x] 音频数据持久化存储
- [x] VAD 客户端模块（与 Python VAD 服务通信）
- [x] ASR模块（Whisper API 调用）
- [x] LLM模块（GPT API 调用）
- [x] TTS模块（TTS API 调用）
- [x] 打断控制模块（并发监听、状态切换）
- [x] 主控流程/状态机
- [x] 语音助手主程序（`cmd/voice_assistant/main.go`）

### 4. 测试与调优
- [x] 音频采集与播放测试
- [x] 音频数据持久化测试
- [x] VAD 功能测试
- [x] ASR 功能测试
- [x] LLM 功能测试
- [x] TTS 功能测试
- [x] 语音助手完整流程测试
- [x] 打断功能集成
- [ ] 性能与延迟优化

### 5. 文档与说明
- [x] 项目结构说明
- [x] 音频模块功能说明
- [x] VAD 模块功能说明
- [x] ASR 模块功能说明
- [x] LLM 模块功能说明
- [x] TTS 模块功能说明
- [x] 语音助手完整指南（`docs/VOICE_ASSISTANT.md`）
- [x] 环境搭建与运行说明
- [x] 常见问题与调试指南

---

## 七、后续可扩展方向

- 支持多语言
- 支持本地 Whisper/LLM/TTS（如有算力）
- 增加热词、上下文记忆等高级功能
- 优化音频数据持久化存储（支持压缩、加密等）
- 添加音频数据缓存机制，提高响应速度

## 八、通义千问集成 ✅

### 8.1 集成状态
- [x] **LLM 模块**：通义千问大语言模型客户端 (`internal/llm/qwen_client.go`)
- [x] **ASR 模块**：通义千问语音识别客户端 (`internal/asr/qwen_client.go`)  
- [x] **TTS 模块**：通义千问语音合成客户端 (`internal/tts/qwen_client.go`)
- [x] **演示程序**：完整的通义千问语音助手演示 (`cmd/qwen_voice_assistant/main.go`)
- [x] **文档说明**：详细的集成指南 (`docs/QWEN_INTEGRATION.md`)

### 8.2 支持的功能
- ✅ **多模型支持**：qwen-turbo, qwen-plus, qwen-max 等
- ✅ **多语言识别**：中文、英文、日文等 17 种语言
- ✅ **多音色合成**：10+ 种中文音色选择
- ✅ **接口兼容**：与 OpenAI 客户端接口完全兼容
- ✅ **错误处理**：完善的错误处理和重试机制

### 8.3 使用方式
```bash
# 设置 API Key
export QWEN_API_KEY="sk-your-api-key"

# 运行演示程序
go run cmd/qwen_voice_assistant/main.go
```

### 8.4 技术特点
- **无缝切换**：可以轻松从 OpenAI API 切换到通义千问
- **统一接口**：所有客户端实现相同的接口规范
- **类型安全**：完整的 Go 类型定义和错误处理
- **文档完善**：详细的使用说明和最佳实践

## 九、OpenAI SDK 集成 ✅

### 9.1 集成状态
- [x] **LLM 模块**：官方 OpenAI Go SDK 客户端 (`internal/llm/openai_sdk_client.go`)
- [x] **ASR 模块**：官方 OpenAI Go SDK 语音识别客户端 (`internal/asr/openai_sdk_client.go`)  
- [x] **TTS 模块**：官方 OpenAI Go SDK 语音合成客户端 (`internal/tts/openai_sdk_client.go`)
- [x] **演示程序**：完整的 OpenAI SDK 功能演示 (`cmd/openai_sdk_full_demo/main.go`)
- [x] **文档说明**：详细的集成指南 (`docs/OPENAI_SDK_INTEGRATION.md`)

### 9.2 主要优势
- ✅ **官方支持**：使用 OpenAI 官方维护的 Go SDK
- ✅ **更高稳定性**：及时获得最新功能和安全更新
- ✅ **更好性能**：优化的网络处理和错误恢复
- ✅ **类型安全**：完整的 Go 类型定义和错误处理
- ✅ **接口兼容**：与现有客户端接口完全兼容

### 9.3 支持的功能

#### LLM 功能
- **模型支持**：gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-4, gpt-3.5-turbo 等
- **对话功能**：简单对话、系统消息、连续对话、自定义参数
- **工具功能**：Token 估算、文本截断、API Key 验证

#### ASR 功能  
- **模型支持**：whisper-1
- **语言支持**：100+ 种语言（中文、英文、日文等）
- **输入格式**：音频数据、音频文件
- **自定义参数**：语言指定、温度控制、提示词等

#### TTS 功能
- **模型支持**：tts-1, tts-1-hd
- **音色支持**：6 种音色（alloy, echo, fable, onyx, nova, shimmer）
- **格式支持**：mp3, opus, aac, flac, wav, pcm
- **参数控制**：语速调节、音色选择、格式指定

### 9.4 使用方式
```bash
# 设置 API Key
export OPENAI_API_KEY="sk-your-api-key"

# 运行演示程序
go run cmd/openai_sdk_full_demo/main.go
```

### 9.5 技术特点
- **无缝切换**：可以轻松从自定义客户端切换到官方 SDK
- **统一接口**：所有客户端实现相同的接口规范
- **类型安全**：完整的 Go 类型定义和错误处理
- **文档完善**：详细的使用说明和最佳实践
- **性能优化**：连接复用、超时控制、并发管理

### 9.6 与现有方案对比

| 特性 | 自定义客户端 | OpenAI SDK | 通义千问 |
|------|-------------|------------|----------|
| 官方支持 | ❌ | ✅ | ✅ |
| 稳定性 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| 功能完整性 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| 中文优化 | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| 成本 | 💰💰💰 | 💰💰💰 | 💰💰 |
| 延迟 | 🌐 | 🌐 | 🇨🇳 |

### 9.7 推荐使用场景
- **生产环境**：推荐使用 OpenAI SDK，获得最佳稳定性
- **国际化应用**：OpenAI SDK 支持更多语言和地区
- **最新功能**：及时获得 OpenAI 最新 API 特性
- **企业级应用**：官方支持，更好的技术保障

---
