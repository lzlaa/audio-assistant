# 语音助手项目方案设计文档

## 一、总体架构

```
┌────────────┐      ┌────────────┐      ┌────────────┐      ┌────────────┐      ┌────────────┐
│ 麦克风输入 │─音频→│ 语音活动检测│─音频→│ 语音识别ASR │─文本→│ 语言模型LLM │─文本→│ 文本转语音TTS│─音频→│ 扬声器播放 │
└────────────┘      └────────────┘      └────────────┘      └────────────┘      └────────────┘
         ↑                                                                                   │
         └─────────────────────<─────打断检测─────<───────────────────────────────────────────┘
```

- **麦克风输入**：采集用户语音。
- **VAD（语音活动检测）**：用 Silero VAD 检测用户是否在说话，自动分割语音片段。
- **ASR（语音识别）**：用 OpenAI Whisper API 将语音转为文本。
- **LLM（大语言模型）**：用 OpenAI GPT API 生成回复文本。
- **TTS（文本转语音）**：用 OpenAI/TTS API 将回复文本转为语音。
- **扬声器播放**：播放助手回复。
- **打断机制**：如果用户在助手说话时再次说话，立即打断助手发言，重新进入识别流程。

---

## 二、模块划分

1. **音频采集模块**  
   - 负责从本地麦克风实时采集音频流。
   - 技术选型：Go + [portaudio-go](https://github.com/gordonklaus/portaudio)
   - 状态：✅ 已完成

2. **VAD模块（Silero VAD）**  
   - 检测音频流中何时开始/结束说话。
   - 技术选型：Go 调用 Python Silero VAD（通过 HTTP 通信）
   - 状态：✅ 已完成

3. **ASR模块（Whisper）**  
   - 将检测到的语音片段发送到 OpenAI Whisper API，获取文本。
   - 技术选型：Go HTTP 客户端
   - 状态：⏳ 待实现

4. **LLM模块（GPT）**  
   - 将识别到的文本发送到 OpenAI GPT API，获取回复文本。
   - 技术选型：Go HTTP 客户端
   - 状态：⏳ 待实现

5. **TTS模块**  
   - 将回复文本发送到 TTS API，获取语音音频。
   - 技术选型：Go HTTP 客户端
   - 状态：⏳ 待实现

6. **音频播放模块**  
   - 播放助手回复的音频。
   - 技术选型：Go + portaudio-go
   - 状态：✅ 已完成

7. **打断控制模块**  
   - 检测用户是否在助手说话时插话，若有则立即停止播放并重新进入识别流程。
   - 技术选型：Go 协程、通道、状态机
   - 状态：✅ 已完成

8. **主控流程/状态机**  
   - 协调各模块，保证流程顺畅，处理异常和状态切换。
   - 状态：✅ 已完成

---

## 三、技术选型说明

- **Go语言**：主程序开发，易于并发、跨平台。
- **portaudio-go**：音频采集与播放。
- **Silero VAD**：用 Python 实现，Go 通过 gRPC/HTTP/子进程调用。
- **OpenAI API**：Whisper（ASR）、GPT（LLM）、TTS。
- **gRPC/HTTP**：Go 与 Python 进程通信。

---

## 四、数据流与状态流

1. **采集音频流** → 2. **VAD检测说话段** → 3. **说话结束后自动送ASR** → 4. **ASR转文本** → 5. **LLM生成回复** → 6. **TTS转语音** → 7. **播放音频**  
   - **播放期间**：持续监听麦克风，若检测到用户说话，立即打断播放，回到第1步。

---

## 五、关键难点说明

- **VAD与Go集成**：Silero VAD官方无Go实现，需用Python服务，Go通过gRPC/HTTP/子进程调用。
- **打断机制**：需用Go并发特性，播放时持续监听VAD，检测到说话立即打断。
- **音频流管理**：需处理音频缓冲、格式转换等细节。
- **API调用速率与错误处理**：需处理API延迟、失败重试等。

---

## 六、TODO List

### 1. 环境准备
- [x] 安装 Go 环境
- [x] 安装 Python 环境
- [x] 安装 portaudio（Go 和 Python 都需）
- [ ] 注册 OpenAI API Key
- [ ] 下载/准备 Silero VAD Python 脚本

### 2. VAD 服务
- [x] 用 Python 实现 Silero VAD 服务（HTTP 方式）
- [x] 测试本地音频流通过 VAD 服务能正确检测说话段

### 3. Go 主程序
- [x] 音频采集模块（portaudio-go）
- [x] 音频播放模块（portaudio-go）
- [x] 音频数据持久化存储
- [x] VAD 客户端模块（与 Python VAD 服务通信）
- [ ] ASR模块（Whisper API 调用）
- [ ] LLM模块（GPT API 调用）
- [ ] TTS模块（TTS API 调用）
- [x] 打断控制模块（并发监听、状态切换）
- [x] 主控流程/状态机

### 4. 测试与调优
- [x] 音频采集与播放测试
- [x] 音频数据持久化测试
- [x] VAD 功能测试
- [ ] ASR 功能测试
- [ ] LLM 功能测试
- [ ] TTS 功能测试
- [ ] 打断功能测试
- [ ] 性能与延迟优化

### 5. 文档与说明
- [x] 项目结构说明
- [x] 音频模块功能说明
- [x] VAD 模块功能说明
- [ ] ASR 模块功能说明
- [ ] LLM 模块功能说明
- [ ] TTS 模块功能说明
- [ ] 环境搭建与运行说明
- [ ] 常见问题与调试指南

---

## 七、后续可扩展方向

- 支持多语言
- 支持本地 Whisper/LLM/TTS（如有算力）
- 增加热词、上下文记忆等高级功能
- 优化音频数据持久化存储（支持压缩、加密等）
- 添加音频数据缓存机制，提高响应速度
